{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your name:\n",
    "Cindy Yang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Single PE Modeling\n",
    "We will start with a simple design consisting of a single PE as shown in the figure below. The PE contains a MAC unit to do multiplication and accumulation, and a scratchpad to store data locally for reuse. We also provide you with the loop nest for this single PE design in the figure below. Please find the necessary Accelergy/Timeloop descriptions at `designs/singlePE`.\n",
    "\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img align=\"left\" src=\"designs/singlePE/figures/PE_arch.png\" alt=\"PE Architecture\" style=\"margin:100px 0px 30px 70px; width:35%\">\n",
    "  </div>\n",
    "  <div class=\"column\">\n",
    "    <img  align=\"left\"  src=\"designs/singlePE/figures/PE_loopnest.png\" alt=\"PE Loopnest\" style=\"width:40%\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1\n",
    "Assuming you cannot reorder the provided loop nest, if you can only store one datatype (datatypes inlcude *filter weights, input activations, output activations*) inside the PE scratchpad to maximize data reuse inside the PE, which datatye will you choose? In 1 or 2 sentences, explain why.\n",
    "\n",
    "I would choose the filter weights because the outermost 4 loops correspond to the indices for the weight values, so the computation is weight stationary. If we keep the weights on the PE, we will be able to repeatedly reuse them before switching out the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2 \n",
    "Take a look at the `design/singlePE/arch/single_PE_arch.yaml` file. This file describes the hardware structure of the architecture. Please fill in the chart below:\n",
    "\n",
    "*Hint: the operand registers of the mac unit belong to the same memory level*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of memory levels (including DRAM and registers)    # of bits used to represent a data    size of local scrachpad (bytes)\n",
      "                        3                                            16                                  36                \n"
     ]
    }
   ],
   "source": [
    "# the Question 1.2 chart\n",
    "d = {'# of memory levels (including DRAM and registers)': [3],   # DRAM, registers \n",
    "     '  # of bits used to represent a data': [16],                # fill in your answer here\n",
    "     '  size of local scrachpad (bytes)': [36],                   # fill in your answer here\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df.to_string(index=False, justify='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the compound component descriptions at `designs/singlePE/arch/components`. These files describe the hardware details of each component in the design. \n",
    "\n",
    "1. Are these compound components composed of single subcomponent or multiple subcomponents?\n",
    "   \n",
    "   These components are each composed of a single subcomponent\n",
    "   \n",
    "\n",
    "2. According to description of the `mac_compute` compound component, is our architecture capable of performing floating point computations? In 1 or 2 sentences, explain why.\n",
    "\n",
    "    No, its single component is of class 'intmac', which is for integer computations only.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3\n",
    "The command below performs static hardware charaterizations using **Accelergy**. You do not need to worry about the warning messages.\n",
    "\n",
    "Examine the file `designs/singlePE/output/ERT.yaml`. Please fill in the chart below (**note that the implicit energy unit for the ERT is pJ**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    _                _                      \n",
      "   / \\   ___ ___ ___| | ___ _ __ __ _ _   _ \n",
      "  / _ \\ / __/ __/ _ \\ |/ _ \\ '__/ _` | | | |\n",
      " / ___ \\ (_| (_|  __/ |  __/ | | (_| | |_| |\n",
      "/_/   \\_\\___\\___\\___|_|\\___|_|  \\__, |\\__, |\n",
      "                                |___/ |___/ \n",
      "\n",
      "Info: generating outputs according to the following specified output flags... \n",
      " Please use the -f flag to update the preference (default to all output files) \n",
      "{'ERT': 1, 'ERT_summary': 1, 'ART': 1, 'ART_summary': 1, 'energy_estimation': 1, 'flattened_arch': 1}\n",
      "Info: Parsing file arch/single_PE_arch.yaml for architecture info \n",
      "Info: Parsing file arch/components/mac_compute.yaml for compound_components info \n",
      "Info: Parsing file arch/components/reg_storage.yaml for compound_components info \n",
      "Info: Parsing file arch/components/smart_storage.yaml for compound_components info \n",
      "Info: config file located: /home/workspace/.config/accelergy/accelergy_config.yaml \n",
      "config file content: \n",
      " {'estimator_plug_ins': ['/usr/local/share/accelergy/estimation_plug_ins'], 'primitive_components': ['/usr/local/share/accelergy/primitive_component_libs'], 'table_plug_ins': {'roots': ['/usr/local/share/accelergy/estimation_plug_ins/accelergy-table-based-plug-ins/set_of_table_templates', '/home/workspace/lab4/PIM_estimation_tables']}, 'version': 0.3}\n",
      "Info: primitive component file parsed:  /usr/local/share/accelergy/primitive_component_libs/primitive_component.lib.yaml \n",
      "Info: primitive component file parsed:  /usr/local/share/accelergy/primitive_component_libs/soc_primitives.lib.yaml \n",
      "Info: primitive component file parsed:  /usr/local/share/accelergy/primitive_component_libs/pim_primitive_component.lib.yaml \n",
      "Info: estimator plug-in identified by:  /usr/local/share/accelergy/estimation_plug_ins/accelergy-cacti-plug-in/cacti.estimator.yaml \n",
      "Info: estimator plug-in identified by:  /usr/local/share/accelergy/estimation_plug_ins/dummy_tables/dummy.estimator.yaml \n",
      "Info: estimator plug-in identified by:  /usr/local/share/accelergy/estimation_plug_ins/accelergy-table-based-plug-ins/table.estimator.yaml \n",
      "table-based-plug-ins Identifies a set of tables named:  test_tables\n",
      "table-based-plug-ins Identifies a set of tables named:  32nm_tables\n",
      "table-based-plug-ins Identifies a set of tables named:  memristor_tables\n",
      "Info: estimator plug-in identified by:  /usr/local/share/accelergy/estimation_plug_ins/accelergy-aladdin-plug-in/aladdin.estimator.yaml \n",
      "Warn: No action counts are specified as yaml input \n",
      "Info: flattened architecture is saved to: output/flattened_architecture.yaml \n",
      "Info: energy reference table is saved to: output/ERT.yaml \n",
      "Info: energy reference table summary is saved to: output/ERT_summary.yaml \n",
      "Warn: no runtime energy estimations are generated... not generating energy_estimation.yaml \n",
      "Info: area reference table is saved to: output/ART.yaml \n",
      "Info: area reference table summary is saved to: output/ART_summary.yaml \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd designs/singlePE/\n",
    "accelergy arch/ -o output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DRAM read   DRAM write   scrachpad read   scrachpad write   mac compute\n",
      "   512         512           0.226             0.226           3.275    \n"
     ]
    }
   ],
   "source": [
    "# the Question 1.3 chart\n",
    "d = {'DRAM read': [512],           # fill in your answer here\n",
    "     ' DRAM write': [512],         # fill in your answer here\n",
    "     ' scrachpad read': [0.226],     # fill in your answer here\n",
    "     ' scrachpad write': [0.226],    # fill in your answer here\n",
    "     ' mac compute': [3.275],        # fill in your answer here\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df.to_string(index=False, justify='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.4 \n",
    "\n",
    "Take a look at the `design/singlePE/map/map.yaml` file. This file describes a mapping for a certain workload. By examining the mapping, can you tell what are the values of `M0`, `N0`, `C0`, `R`, `S`, `P`, `Q` in the loop nest above? For each of them, if you can, specifiy the value in the following chart; if you can't, state why in this cell. \n",
    "\n",
    "provide your explanantion to why you cannot tell some of the values here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " M0  N0  C0                            S                                                       R                                                    P                                                  Q                         \n",
      " 2   1   1  Factor set to 0, varies depending on weight tensor size Factor set to 0, varies depending on weight tensor size Factor set to 0, varies depending on workload size Factor set to 0, varies depending on workload size\n"
     ]
    }
   ],
   "source": [
    "# the Question 1.4 chart, put down nan if you cannot tell what the value is \n",
    "d = {'M0': [2],   # fill in your answer here\n",
    "     'N0': [1],   # fill in your answer here\n",
    "     'C0': [1],   # fill in your answer here\n",
    "     'S':  ['Factor set to 0, varies depending on weight tensor size'],   # fill in your answer here\n",
    "     'R':  ['Factor set to 0, varies depending on weight tensor size'],   # fill in your answer here\n",
    "     'P':  ['Factor set to 0, varies depending on workload size'],   # fill in your answer here\n",
    "     'Q':  ['Factor set to 0, varies depending on workload size']    # fill in your answer here\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df.to_string(index=False, justify='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.5\n",
    "The command below performs **Timeloop** runtime simulation of your design, and **Accelergy** is queried as the backend to provide energy estimations for each simulated component (that's why you will see the Accelergy related outputs as well (*e.g.,* `timeloop-model.ERT.yaml`))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Take a look at `timeloop-model.map.txt`, can you now tell the dimensions of the layer shape by looking at the produced mapping? In 1 or 2 sentences, explain why. Take a look at the `timeloop-model.stats.txt`, and fill in the following chart.\n",
    "\n",
    "   Yes, we can see the dimensions of the layer shape, (C=32, M=64, R=3, S=3, P=5, Q=5, N=2), because the timeloop mapping shows the ranges of the loops explicitly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute:/usr/local/bin/accelergy arch/single_PE_arch.yaml arch/components/mac_compute.yaml arch/components/reg_storage.yaml arch/components/smart_storage.yaml map/map.yaml ../../layer_shapes/small_layer.yaml --oprefix timeloop-model. -o ./ > timeloop-model.accelergy.log 2>&1\n",
      "Generate Accelergy ART (area reference table) to replace internal area model.\n",
      "Utilization = 1.00 | pJ/MACC =  392.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Interpreting 0 to mean full problem dimension instead of residue.\n",
      "WARNING: Interpreting 0 to mean full problem dimension instead of residue.\n",
      "WARNING: Interpreting 0 to mean full problem dimension instead of residue.\n",
      "WARNING: Interpreting 0 to mean full problem dimension instead of residue.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd designs/singlePE/\n",
    "timeloop-model arch/*.yaml arch/components/*.yaml map/map.yaml ../../layer_shapes/small_layer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run simulaiton on another layer shape by running the command `timeloop-model arch/*yaml arch/components/*.yaml map/map.yaml ../../layer_shapes/medium_layer.yaml`. **Note that your previous outputs from Timeloop might be overwritten by this run if you don't move it to an output folder**\n",
    "\n",
    "   Fill in the second row in the chart below. Does the `pJ/MACC` value change? In 1 or 2 sentences, explain why. \n",
    "\n",
    "   Yes, the pJ/MACC decreased for medium_layer, which had a larger input/output fmap size than small_layer. Our architecture is weight stationary, and the pJ/MACC for each weight is amortized across all inputs it's applied to, so a larger input/output feature map results in a lower pJ/MACC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute:/usr/local/bin/accelergy arch/single_PE_arch.yaml arch/components/mac_compute.yaml arch/components/reg_storage.yaml arch/components/smart_storage.yaml map/map.yaml ../../layer_shapes/medium_layer.yaml --oprefix timeloop-model. -o ./ > timeloop-model.accelergy.log 2>&1\n",
      "Generate Accelergy ART (area reference table) to replace internal area model.\n",
      "Utilization = 1.00 | pJ/MACC =  387.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Interpreting 0 to mean full problem dimension instead of residue.\n",
      "WARNING: Interpreting 0 to mean full problem dimension instead of residue.\n",
      "WARNING: Interpreting 0 to mean full problem dimension instead of residue.\n",
      "WARNING: Interpreting 0 to mean full problem dimension instead of residue.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd designs/singlePE/\n",
    "timeloop-model arch/*.yaml arch/components/*.yaml map/map.yaml ../../layer_shapes/medium_layer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What's the benefit of allowing a factor of 0, e.g., R=0, in mapping specification (*hint: we used the same `map.yaml` for 2 different layer shapes*)?\n",
    "\n",
    "   It allows for more flexibility in defining the mapping so that a factor can update depending on the workload.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer shape     number of cycles    mac energy total (pJ)    scratchpad total energy (pJ)    DRAM total energy (pJ)    pJ/MACC\n",
      " small_layer        921600                3018240                     16662.53                     353484800          392.02  \n",
      "medium_layer       8294400               27164160                     16662.53                    3186081792          387.46  \n"
     ]
    }
   ],
   "source": [
    "# the Question 1.5.1 and 1.5.2 chart\n",
    "d = {'layer shape': ['small_layer', 'medium_layer'],\n",
    "     '  number of cycles': [921600, 8294400],                # fill in your answer here\n",
    "     '  mac energy total (pJ)': [3018240, 27164160],           # fill in your answer here\n",
    "     '  scratchpad total energy (pJ)': [16662.53, 16662.53],    # fill in your answer here  \n",
    "     '  DRAM total energy (pJ)':  [353484800, 3186081792],         # fill in your answer here  # hint: all datatypes\n",
    "     '  pJ/MACC':  [392.02, 387.46]                         # fill in your answer here\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df.to_string(index=False, justify='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since now you have an understanding of the input and output files of the tools, we now would like you to write your own input files and feed it to the evluation system.**\n",
    "\n",
    "\n",
    "### Question 1.6\n",
    "\n",
    "Many modern accelerator designs integrate address generators into their storages. The address generator is responsible for generating a sequence of read and write addresses for the memory, *i.e.,* for each read and write, the address is generated locally by the address generator. Typically, the address generator can be represented as an adder.\n",
    "\n",
    "In this question, we would like you to update the compound component definition for the scratchpad to reflect the existence of such an additional address generator. To be specific:\n",
    "\n",
    "    1. name of the address generator: address_generator\n",
    "    2. class of the address generator: intadder\n",
    "    3. attributes associated with the address generator: datawidth (hint: log2 function can be used), technology, latency\n",
    "    4. you also need to specify the role your address generator plays when the storage is read and written\n",
    "\n",
    "Navigate to **`designs/singlePE_ag/arch/components/smart_storage.yaml`** to apply your updates...\n",
    "\n",
    "1. After you have updated your architecture description, naviagte to the desgins root folder `designs/singlePE_ag` and run   `accelergy arch/ -o output -v 1` (the command cell below). Examine the `ERT.yaml` and `ERT_summary_verbose.yaml` files in the output folder, and fill in the chart below. \n",
    "\n",
    "\n",
    "2. Without rerunning Timeloop simulation for the `small_layer.yaml` workload, can you infer from the `ERT.yaml` how much more energy will the local scrachpad consume? In 1 or 2 sentences, explain why.\n",
    "\n",
    "   provide your answer here...\n",
    "   \n",
    "  \n",
    "3. If we have a huge workload and running simulations of it takes hours, how would using compound components help us when we perform design space exploration (*hint: can you avoid rerunning simulations when you change the details of a compound component*)?\n",
    "\n",
    "   provide your answer here...\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    _                _                      \n",
      "   / \\   ___ ___ ___| | ___ _ __ __ _ _   _ \n",
      "  / _ \\ / __/ __/ _ \\ |/ _ \\ '__/ _` | | | |\n",
      " / ___ \\ (_| (_|  __/ |  __/ | | (_| | |_| |\n",
      "/_/   \\_\\___\\___\\___|_|\\___|_|  \\__, |\\__, |\n",
      "                                |___/ |___/ \n",
      "\n",
      "Info: generating outputs according to the following specified output flags... \n",
      " Please use the -f flag to update the preference (default to all output files) \n",
      "{'ERT': 1, 'ERT_summary': 1, 'ART': 1, 'ART_summary': 1, 'energy_estimation': 1, 'flattened_arch': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelergy\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('accelergy==0.3', 'console_scripts', 'accelergy')())\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/accelergy/accelergy_console.py\", line 72, in main\n",
      "    raw_dicts = RawInputs2Dicts(raw_input_info)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/accelergy/raw_inputs_2_dicts.py\", line 21, in __init__\n",
      "    self.load_and_construct_dicts()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/accelergy/raw_inputs_2_dicts.py\", line 66, in load_and_construct_dicts\n",
      "    for loaded_content in loaded_content_list:\n",
      "TypeError: 'NoneType' object is not iterable\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'cd designs/singlePE_ag/\\naccelergy arch/ -o output -v 1\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0b3e3f5b8357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cd designs/singlePE_ag/\\naccelergy arch/ -o output -v 1\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/bin/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2397\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2399\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/conda/lib/python3.8/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/conda/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/bin/conda/lib/python3.8/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'cd designs/singlePE_ag/\\naccelergy arch/ -o output -v 1\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd designs/singlePE_ag/\n",
    "accelergy arch/ -o output -v 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [read energy of the scratchpad (pJ), write energy of the scratchpad (pJ), address generation energy (pJ)]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Question 1.6 chart\n",
    "d = {'read energy of the scratchpad (pJ)': [],  # fill in your answer here\n",
    "     'write energy of the scratchpad (pJ)': [], # fill in your answer here\n",
    "     'address generation energy (pJ)': []       # fill in your answer here\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df.to_string(index=False, justify='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.7\n",
    "So far, we have been focusing on studying the dataflow described in the provided loop next above. In this question, we would like you to update the mapping to represent a new loop nest shown below. \n",
    "\n",
    "Navigate to **`designs/singlePE_os/map/map.yaml`**. Please set the bounds in the file according to the layer shape described in `layer_shapes/small_layer.yaml`  (**note that some of the inner bounds are set for you**) and **only keep outputs inside the scratchpad**.\n",
    "\n",
    "After you have updated the mapping, go to `designs/singlePE_os/` and run the command `timeloop-model arch/*yaml arch/components/*.yaml map/map.yaml ../../layer_shapes/small_layer.yaml` to perform runtime simualtions (run the command cell below). Please fill in the chart below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img align=\"center\" src=\"designs/singlePE_os/figures/PE_loopnest.png\" alt=\"PE Architecture\" style=\"margin:0px 0px 70px 70px; width:50%\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute:/usr/local/bin/accelergy arch/single_PE_arch.yaml arch/components/mac_compute.yaml arch/components/reg_storage.yaml arch/components/smart_storage.yaml map/map.yaml ../../layer_shapes/small_layer.yaml --oprefix timeloop-model. -o ./ > timeloop-model.accelergy.log 2>&1\n",
      "Generate Accelergy ART (area reference table) to replace internal area model.\n",
      "Utilization = 1.00 | pJ/MACC =  287.405\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd designs/singlePE_os/\n",
    "timeloop-model arch/*yaml arch/components/*.yaml map/map.yaml ../../layer_shapes/small_layer.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer shape  number of cycles  mac Energy  scratchpad Energy (pJ)  DRAM Energy (pJ)  pJ/MAC\n",
      "small_layer       921600       3018240.0           68704              261734400      287.4 \n"
     ]
    }
   ],
   "source": [
    "# the Question 1.7 chart\n",
    "d = {'layer shape': ['small_layer'],    \n",
    "     'number of cycles': [921600],          # fill in your answer here\n",
    "     'mac Energy':  [3018240.00],               # fill in your answer here\n",
    "     'scratchpad Energy (pJ)': [68704],    # fill in your answer here\n",
    "     'DRAM Energy (pJ)': [261734400],          # fill in your answer here\n",
    "     'pJ/MAC':[287.40]                      # fill in your answer here\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df.to_string(index=False, justify='center'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
